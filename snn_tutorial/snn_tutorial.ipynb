{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2drziIC9BH-2"
      },
      "source": [
        "# Spiking Neural Networks (SNNs): from LIF neuron to a tiny MNIST demo\n",
        "\n",
        "**What you’ll learn:**  \n",
        "- Why SNNs process information as **spikes over time** and where that’s useful.  \n",
        "- The **Leaky Integrate-and-Fire (LIF)** neuron: intuition, equation, and a small simulation.  \n",
        "- How to **encode** numbers/images as **spike trains** (Poisson rate coding).  \n",
        "- How to **train** a small SNN with **surrogate gradients** on MNIST.  \n",
        "- How to **visualise** spikes, voltage traces, and class spike counts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGfbgKPCBPta"
      },
      "source": [
        "## 1. Why SNNs at all (very short)\n",
        "\n",
        "- **Temporal computation:** SNNs process *events through time* (closer to how sensors/brains work).\n",
        "- **Sparsity:** neurons spike only when needed → fewer operations than dense activations.\n",
        "- **Hardware fit:** event-driven neuromorphic chips can execute spikes very efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkzkD5ADBape"
      },
      "source": [
        "## 2. From perceptron to a spiking neuron\n",
        "\n",
        "A classical **perceptron** computes:\n",
        "\n",
        "$\n",
        "y = f(Wx + b),\n",
        "$\n",
        "\n",
        "where $f$ is a continuous activation (e.g. sigmoid, ReLU).\n",
        "\n",
        "In contrast, a spiking neuron integrates input over time — it has memory of its past state.\n",
        "\n",
        "When the membrane potential Vm(t) exceeds a threshold Vth, the neuron emits a spike and resets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu4EJvBzBqNk"
      },
      "source": [
        "### The Leaky Integrate-and-Fire (LIF) neuron\n",
        "\n",
        "We’ll use the **LIF** model later in training. It behaves like an **RC circuit** and can be described using the following differential equation:\n",
        "\n",
        "$$\n",
        "C\\,\\frac{dV_m(t)}{dt} \\;=\\; -\\frac{V_m(t) - E_L}{R} \\;+\\; I(t),\n",
        "\\qquad \\tau_m = RC\n",
        "$$\n",
        "\n",
        "Equivalently,\n",
        "\n",
        "$$\n",
        "\\tau_m \\,\\frac{dV_m}{dt} \\;=\\; -\\big(V_m - E_L\\big) \\;+\\; R\\,I(t).\n",
        "$$\n",
        "\n",
        "**Symbols:**  \n",
        "- $V_m(t)$: membrane voltage (neuron’s internal state)  \n",
        "- $E_L$: leak/rest voltage (decay target)  \n",
        "- $I(t)$: input current (from synaptic spikes)  \n",
        "- $R$: membrane resistance, \\(C\\): membrane capacitance  \n",
        "- $\\tau_m = RC$: membrane time constant (leak speed)\n",
        "\n",
        "**Meaning of terms (at a glance):**  \n",
        "- $R\\,I(t)$: **integration** — input pushes \\(V_m\\) upward  \n",
        "- $-\\big(V_m - E_L\\big)$: **leak** — pulls \\(V_m\\) back toward rest  \n",
        "- **Spike rule:** if $V_m \\ge V_{\\text{th}}$, emit a spike; reset $V_m \\to V_{\\text{reset}}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwSoRbCRZvCV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Params ---\n",
        "T   = 2000           # total steps\n",
        "dt  = 1e-3           # 1 ms bin\n",
        "tau = 0.02           # 20 ms membrane time constant\n",
        "v_th = 1.0           # threshold\n",
        "v_reset = 0.0\n",
        "E_L = 0.0            # rest (leak target)\n",
        "\n",
        "# --- Input current I(t): several plateaus; some > 1.0 to guarantee spikes ---\n",
        "I = np.zeros(T)\n",
        "I[200:350]   += 0.60    # subthreshold: integrates then leaks\n",
        "I[500:650]   += 1.10    # suprathreshold: periodic spiking\n",
        "I[800:950]   += 0.90    # near-threshold: maybe a spike after residual + wiggle\n",
        "I[1200:1600] += 1.20    # longer suprathreshold: clear spike train\n",
        "\n",
        "# gentle sinusoidal wiggle (always nonnegative) to show smooth integration/leak\n",
        "t_arr = np.arange(T)\n",
        "I += 0.05 * (0.5 + 0.5*np.sin(2*np.pi*t_arr/120))   # in [0, 0.05]\n",
        "\n",
        "# --- Simulate LIF with Euler step ---\n",
        "V   = np.zeros(T)\n",
        "spk = np.zeros(T, dtype=bool)\n",
        "\n",
        "for t in range(T-1):\n",
        "    dV = (-(V[t] - E_L) + I[t]) * (dt / tau)    # R=1\n",
        "    V[t+1] = V[t] + dV\n",
        "    if V[t+1] >= v_th:\n",
        "        spk[t+1] = True\n",
        "        V[t+1] = v_reset  # reset after spike\n",
        "\n",
        "time_ms = t_arr * dt * 1000\n",
        "\n",
        "# --- Plot ---\n",
        "fig, ax = plt.subplots(2, 1, figsize=(10,6), sharex=True)\n",
        "\n",
        "ax[0].plot(time_ms, I, label='Input current  $I(t)$')\n",
        "ax[0].set_ylabel('I  (a.u.)')\n",
        "ax[0].legend(loc=\"upper right\")\n",
        "ax[0].grid(alpha=0.3)\n",
        "\n",
        "ax[1].plot(time_ms, V, label='Membrane  $V_m(t)$')\n",
        "ax[1].axhline(v_th, ls='--', c='gray', alpha=0.8, label='threshold')\n",
        "ax[1].vlines(time_ms[spk], ymin=v_reset, ymax=v_th*1.05, color='crimson', alpha=0.7, label='spikes')\n",
        "ax[1].set_xlabel('time (ms)')\n",
        "ax[1].set_ylabel('V')\n",
        "ax[1].legend(loc=\"upper right\")\n",
        "ax[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxWZMVPdYHqd"
      },
      "source": [
        "You should see spikes whenever the input current pushes the membrane potential above threshold.\n",
        "This simple mechanism is the core of how information is transmitted in an SNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yacenDrC_fk"
      },
      "source": [
        "## 3. Encoding Real-Valued Data into Spikes\n",
        "\n",
        "Unlike artificial neural networks (ANNs), which process continuous-valued activations, spiking neural networks (SNNs) require *discrete events* — spikes — as input. Therefore, continuous data (such as pixel intensities or audio amplitudes) must first be transformed into spike trains. This process is known as **neural encoding**.\n",
        "\n",
        "Several biologically inspired encoding schemes have been proposed, each relying on a different principle of how information is represented in spike activity:\n",
        "\n",
        "- **Rate coding:** the information is represented by the *average firing rate* — a higher input value produces a higher spike frequency.\n",
        "- **Temporal coding:** the information is encoded in the *precise timing* of spikes — larger input values result in earlier spikes within a defined time window.\n",
        "\n",
        "In this tutorial, we will employ **rate coding** using a **Poisson spike generator**.  \n",
        "A Poisson process models spike events as random occurrences that follow a specific average rate.  \n",
        "This stochasticity introduces variability similar to biological neurons while maintaining an expected firing rate proportional to the input magnitude.\n",
        "\n",
        "Formally, let the firing rate be denoted as $ \\lambda $ (in spikes per second) and the time step be \\( dt \\).  \n",
        "The probability of emitting a spike in a small interval $ dt $ is given by\n",
        "\n",
        "$$\n",
        "p = \\min(\\lambda \\, dt, \\, 1).\n",
        "$$\n",
        "\n",
        "In practice, $ \\lambda $ is derived from the input value (for instance, a pixel brightness scaled to a maximum firing rate).  \n",
        "At each time step, we sample a random number from a uniform distribution in \\([0,1)\\); if it is less than \\( p \\), a spike is generated.  \n",
        "This yields a **Poisson-distributed spike train** whose mean firing rate encodes the input intensity but with biologically realistic variability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VqlKQpIBuOY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def poisson_encode(images, num_steps, max_rate_hz=100.0, dt=1e-3, rng=None):\n",
        "    \"\"\"\n",
        "    Encode continuous-valued images into Poisson spike trains.\n",
        "\n",
        "    Args:\n",
        "        images (torch.Tensor): [B, *] tensor with values in [0,1]\n",
        "        num_steps (int): number of simulation time steps\n",
        "        max_rate_hz (float): maximum firing rate corresponding to pixel=1.0\n",
        "        dt (float): duration of a single time step (in seconds)\n",
        "        rng (torch.Generator, optional): random number generator for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        spikes (torch.BoolTensor): [T, B, N] tensor of spike trains\n",
        "    \"\"\"\n",
        "    if images.dim() > 2:\n",
        "        B = images.size(0)\n",
        "        N = images[0].numel()\n",
        "        flat = images.view(B, -1)\n",
        "    else:\n",
        "        B, N = images.shape\n",
        "        flat = images\n",
        "\n",
        "    if rng is None:\n",
        "        rng = torch.Generator(device=images.device)\n",
        "\n",
        "    lam = flat * max_rate_hz               # [B, N]\n",
        "    p = torch.clamp(lam * dt, 0.0, 1.0)    # [B, N]\n",
        "\n",
        "    # sample T independent Bernoulli trials per pixel\n",
        "    rand = torch.rand((num_steps, B, N), generator=rng, device=images.device)\n",
        "    spikes = rand < p                       # [T, B, N], bool\n",
        "    return spikes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsuF33kxDTbM"
      },
      "source": [
        "## 4. MNIST as a Temporally Encoded Dataset\n",
        "\n",
        "The MNIST dataset consists of **static** grayscale images $ \\mathbf{x} \\in [0,1]^{28\\times 28} $.  \n",
        "Spiking neural networks (SNNs), however, operate on **temporal event streams**. To bridge this mismatch, we convert each pixel $x_i$ into a **Poisson spike train** whose average firing rate is proportional to its intensity.\n",
        "\n",
        "Let $ f_{\\max} $ denote the maximum firing rate (in Hz), and let $ dt $ be the simulation time step (in seconds).  \n",
        "For pixel $ i $, we define the rate:\n",
        "\n",
        "$$\n",
        "\\lambda_i = x_i \\, f_{\\max}, \\qquad \\lambda_i \\ge 0,\n",
        "$$\n",
        "\n",
        "and generate spikes by drawing, at each discrete time step, an independent Bernoulli trial with success probability:\n",
        "\n",
        "$$\n",
        "p_i = \\min(\\lambda_i \\, dt,\\, 1).\n",
        "$$\n",
        "\n",
        "Across a window of $T$ steps, the expected spike count for pixel $ i $ is:\n",
        "\n",
        "$$\n",
        "\\mathbb{E}[N_i] = \\lambda_i \\, T \\, dt = x_i \\, f_{\\max} \\, T \\, dt,\n",
        "$$\n",
        "\n",
        "so **brighter pixels produce more spikes on average**, preserving the spatial structure statistically over time.\n",
        "\n",
        "**Why re-draw Poisson realisations each epoch?**  \n",
        "Because the Poisson generator is stochastic, re-sampling for the same image at each epoch acts as **regularisation / data augmentation**: the label remains fixed while the precise spike times vary. The network is thus encouraged to learn the **rate-coded structure** (the invariant intensity pattern) rather than overfitting to a single realisation of spike times.\n",
        "\n",
        "> **Assumptions.** This encoding assumes conditionally independent spikes across pixels and time given $ \\lambda $ (i.e., a discrete-time Poisson process). While simplified relative to the bilogical setting, it is standard and effective for SNN training on static images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPRU7j7HcZWS"
      },
      "outputs": [],
      "source": [
        "# --- MNIST loading (values in [0,1]) ---\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.ToTensor()  # keeps pixels in [0,1]\n",
        "train_ds = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "\n",
        "subset_size = 10000  # e.g. 10k out of 60k\n",
        "indices = torch.randperm(len(train_ds))[:subset_size]\n",
        "train_ds = Subset(train_ds, indices)\n",
        "\n",
        "test_ds  = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "len(train_loader), len(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmb_oM8RcaUE"
      },
      "outputs": [],
      "source": [
        "# --- Example: encode one minibatch for T time steps (re-draw every call/epoch) ---\n",
        "num_steps = 100\n",
        "dt = 1e-3\n",
        "max_rate_hz = 100.0\n",
        "\n",
        "batch_imgs, batch_labels = next(iter(train_loader))\n",
        "batch_imgs = batch_imgs.to(device)   # [B,1,28,28]\n",
        "spikes = poisson_encode(batch_imgs, num_steps=num_steps, max_rate_hz=max_rate_hz, dt=dt)  # [T,B,784]\n",
        "spikes.shape, batch_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUWOq8-mcdP3"
      },
      "outputs": [],
      "source": [
        "# --- Visualisation: original image, spike raster (time × pixels), and spike-rate map ---\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# pick the first sample in the batch\n",
        "img0 = batch_imgs[0]                  # [1,28,28]\n",
        "lab0 = batch_labels[0].item()\n",
        "spk0 = spikes[:, 0]                   # [T, 784]\n",
        "spk0_img = spk0.view(num_steps, 28, 28)\n",
        "\n",
        "# spike count per pixel across time (estimate of rate × window)\n",
        "spk_count_map = spk0_img.sum(dim=0).cpu()\n",
        "\n",
        "fig = plt.figure(figsize=(11,3.6))\n",
        "\n",
        "# Original image\n",
        "ax1 = plt.subplot(1,3,1)\n",
        "ax1.imshow(img0.squeeze().cpu(), cmap=\"gray\")\n",
        "ax1.set_title(f\"MNIST image (label={lab0})\")\n",
        "ax1.axis(\"off\")\n",
        "\n",
        "# Spike raster as time × pixel-index image (flattened spatially)\n",
        "ax2 = plt.subplot(1,3,2)\n",
        "ax2.imshow(spk0.cpu().T, aspect=\"auto\", interpolation=\"nearest\", cmap=\"gray_r\")\n",
        "ax2.set_title(\"Spike raster (time × pixels)\")\n",
        "ax2.set_xlabel(\"Time step\")\n",
        "ax2.set_ylabel(\"Pixel index\")\n",
        "\n",
        "# Spike count map (approx. rate over window)\n",
        "ax3 = plt.subplot(1,3,3)\n",
        "im = ax3.imshow(spk_count_map, cmap=\"viridis\")\n",
        "ax3.set_title(\"Spike counts per pixel\\n(∝ intensity × window)\")\n",
        "ax3.axis(\"off\")\n",
        "plt.colorbar(im, ax=ax3, fraction=0.046, pad=0.04)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjjxD-XYZRDC"
      },
      "source": [
        "## 5. Training a Spiking Neural Network on MNIST\n",
        "\n",
        "Now that we can represent MNIST digits as spike trains, we can train a simple spiking neural network (SNN) to classify them.  \n",
        "Our architecture will consist of two fully connected layers with leaky integrate-and-fire (LIF) neurons:\n",
        "\n",
        "$$\n",
        "\\text{Input spikes (784)} \\;\\longrightarrow\\; \\text{Linear} \\;\\longrightarrow\\; \\text{LIF} \\;\\longrightarrow\\; \\text{Linear} \\;\\longrightarrow\\; \\text{LIF (10 outputs)}\n",
        "$$\n",
        "\n",
        "Each of the ten output neurons corresponds to one digit class (0–9).  \n",
        "During the simulation window of $T$ time steps, the network produces spikes at its output layer.  \n",
        "We estimate class probabilities by **counting spikes per output neuron** over time and predicting the class with the **highest total spike count**:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\arg\\max_{k \\in \\{0,\\ldots,9\\}} \\sum_{t=1}^{T} s_k(t),\n",
        "$$\n",
        "\n",
        "where $s_k(t) \\in \\{0,1\\}$ is the binary spike output of neuron $k$ at time step $t$.\n",
        "\n",
        "---\n",
        "\n",
        "### The challenge of non-differentiability\n",
        "\n",
        "The spike generation function is a **Heaviside step function**:\n",
        "\n",
        "$$\n",
        "s(t) = H(V_m(t) - V_{\\text{th}}) =\n",
        "\\begin{cases}\n",
        "1, & V_m(t) \\ge V_{\\text{th}}, \\\\\n",
        "0, & V_m(t) < V_{\\text{th}},\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "which is **non-differentiable**. Its derivative is the **Dirac delta function**:\n",
        "\n",
        "$$\n",
        "\\frac{ds}{dV_m} = \\delta(V_m - V_{\\text{th}}),\n",
        "$$\n",
        "\n",
        "and therefore zero almost everywhere. This makes direct gradient-based training impossible — gradients would vanish for nearly all membrane potentials, resulting in so-called *dead neurons*.\n",
        "\n",
        "---\n",
        "\n",
        "### Surrogate gradients\n",
        "\n",
        "To enable backpropagation through spikes, modern SNNs use **surrogate gradient methods**.  \n",
        "The idea is to replace the true derivative of the step function with a **smooth, differentiable approximation**, such as:\n",
        "\n",
        "$$\n",
        "\\frac{ds}{dV_m} \\approx \\frac{1}{(1 + \\alpha |V_m - V_{\\text{th}}|)^2},\n",
        "$$\n",
        "\n",
        "where $\\alpha$ controls the steepness of the approximation.  \n",
        "This modification allows gradient-based learning using standard optimizers (e.g., Adam), while maintaining biologically inspired spiking dynamics during the forward pass.\n",
        "\n",
        "---\n",
        "\n",
        "### Practical setup\n",
        "\n",
        "We will use the `snnTorch` library, which provides efficient implementations of the LIF neuron model and surrogate-gradient learning.  \n",
        "The training process will proceed as follows:\n",
        "\n",
        "1. **Encode** each image into Poisson spike trains.  \n",
        "2. **Propagate** spikes through the network for $T$ time steps.  \n",
        "3. **Compute** the loss between the predicted and true labels.  \n",
        "4. **Update** network parameters via backpropagation using surrogate gradients.\n",
        "\n",
        "This framework keeps the temporal dynamics of spiking neurons while making learning possible with standard deep-learning toolchains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uacUW18ftS0"
      },
      "source": [
        "### 5.1 Model definition (Linear → LIF → Linear → LIF)\n",
        "\n",
        "We implement a compact feed-forward SNN:\n",
        "\n",
        "$$\n",
        "\\text{Input }(784) \\;\\to\\; \\text{Linear} \\;\\to\\; \\text{LIF} \\;\\to\\; \\text{Linear} \\;\\to\\; \\text{LIF (10 outputs)}.\n",
        "$$\n",
        "\n",
        "The forward pass expects spike trains of shape $[T, B, N]$ (time, batch, features).  \n",
        "At each time step, spikes are propagated through the two LIF layers; we record the output spikes $\\;s_k(t)\\;$ to compute a **count-based loss** and predictions:\n",
        "\n",
        "$$\n",
        "\\hat{y} \\;=\\; \\arg\\max_{k} \\sum_{t=1}^{T} s_k(t).\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zQ5UNakmEFWH"
      },
      "outputs": [],
      "source": [
        "!pip install snntorch==0.9.4 torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUMI4wu0fpt5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "import snntorch.functional as SF\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device: CPU by default, GPU if available (code works in both)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "torch.manual_seed(0)\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn36QtIFgWSm"
      },
      "source": [
        "#### SNN module\n",
        "\n",
        "We implement two `nn.Linear` layers interleaved with two `snn.Leaky` (LIF) neurons.  \n",
        "We use the **surrogate gradient** provided by snnTorch internally, with decay parameter $\\beta \\in (0,1)$ controlling the membrane leak."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a52eDVcdgaVk"
      },
      "outputs": [],
      "source": [
        "class TinySNN(nn.Module):\n",
        "    def __init__(self, in_dim=28*28, hidden=128, out_dim=10, beta_hidden=0.9, beta_out=0.9):\n",
        "        super().__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.hidden = hidden\n",
        "        self.out_dim = out_dim\n",
        "\n",
        "        self.fc1  = nn.Linear(in_dim, hidden, bias=True)\n",
        "        self.lif1 = snn.Leaky(beta=beta_hidden, spike_grad=surrogate.fast_sigmoid())\n",
        "        self.fc2  = nn.Linear(hidden, out_dim, bias=True)\n",
        "        self.lif2 = snn.Leaky(beta=beta_out, spike_grad=surrogate.fast_sigmoid())\n",
        "\n",
        "    def forward(self, x_seq, return_mem=False):\n",
        "        \"\"\"\n",
        "        x_seq: [T, B, N] spike trains (bool or float)\n",
        "        returns:\n",
        "            spk_out: [T, B, out_dim]\n",
        "            if return_mem=True: also (mem1, mem2) traces\n",
        "        \"\"\"\n",
        "        T, B, N = x_seq.shape\n",
        "        assert N == self.in_dim, f\"Expected input dim {self.in_dim}, got {N}\"\n",
        "\n",
        "        # Initialise LIF hidden states at t=0\n",
        "        mem1 = self.lif1.init_leaky()   # no args in snnTorch 0.9.4\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "\n",
        "        spk_rec = []\n",
        "        mem1_rec = [] if return_mem else None\n",
        "        mem2_rec = [] if return_mem else None\n",
        "\n",
        "        for t in range(T):\n",
        "            x_t = x_seq[t].float()               # [B, N]\n",
        "            h1 = self.fc1(x_t)\n",
        "            spk1, mem1 = self.lif1(h1, mem1)\n",
        "            h2 = self.fc2(spk1)\n",
        "            spk2, mem2 = self.lif2(h2, mem2)\n",
        "\n",
        "            spk_rec.append(spk2)\n",
        "\n",
        "            if return_mem:\n",
        "                mem1_rec.append(mem1)\n",
        "                mem2_rec.append(mem2)\n",
        "\n",
        "        spk_rec = torch.stack(spk_rec, dim=0)    # [T, B, out_dim]\n",
        "\n",
        "        if return_mem:\n",
        "            mem1_rec = torch.stack(mem1_rec, dim=0)  # [T, B, hidden]\n",
        "            mem2_rec = torch.stack(mem2_rec, dim=0)  # [T, B, out_dim]\n",
        "            return spk_rec, (mem1_rec, mem2_rec)\n",
        "\n",
        "        return spk_rec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Dj_DlogaLO"
      },
      "source": [
        "### 5.2 Data pipeline and training loop\n",
        "\n",
        "- **Input:** MNIST, normalized to $[0,1]$.\n",
        "- **Encoding:** Poisson rate encoding for $T$ time steps (re-sampled each iteration).\n",
        "- **Loss:** Cross-entropy on **spike counts** (sum over time), i.e., logits $=\\sum_t s_k(t)$.\n",
        "- **Prediction:** $\\arg\\max_k$ of spike counts over the window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzwnD8aMnDnj"
      },
      "outputs": [],
      "source": [
        "model = TinySNN().to(device)\n",
        "\n",
        "# Training hyperparameters\n",
        "NUM_STEPS   = 50      # time steps T\n",
        "DT          = 1e-3    # 1 ms\n",
        "MAX_RATE_HZ = 100.0   # max firing rate for pixel=1\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "# Cross-entropy on spike *counts* over time\n",
        "# (snnTorch helper: ce_count_loss)\n",
        "loss_fn = SF.ce_count_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rMXk_RBnRFx"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train_one_epoch(epoch):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_seen = 0\n",
        "\n",
        "    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False):\n",
        "        imgs   = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Poisson encode: [T, B, 784]\n",
        "        spikes = poisson_encode(\n",
        "            imgs, num_steps=NUM_STEPS,\n",
        "            max_rate_hz=MAX_RATE_HZ, dt=DT\n",
        "        ).to(device)\n",
        "\n",
        "        # Forward: [T, B, 10]\n",
        "        spk_rec = model(spikes)\n",
        "\n",
        "        # Loss: snnTorch cross-entropy on spike counts\n",
        "        loss = loss_fn(spk_rec, labels)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # --- Metrics (correct decoding) ---\n",
        "        with torch.no_grad():\n",
        "            counts = spk_rec.sum(dim=0)          # [B,10]\n",
        "            preds  = counts.argmax(dim=1)        # [B]\n",
        "            total_correct += (preds == labels).sum().item()\n",
        "            total_seen    += labels.size(0)\n",
        "            total_loss    += loss.item() * labels.size(0)\n",
        "\n",
        "        # free graph\n",
        "        del spikes, spk_rec, loss\n",
        "\n",
        "    avg_loss = total_loss / total_seen\n",
        "    acc = total_correct / total_seen\n",
        "    print(f\"Epoch {epoch}: train loss={avg_loss:.4f} acc={acc:.4f}\")\n",
        "\n",
        "    return avg_loss, acc\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate():\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_seen = 0\n",
        "\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs   = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        spikes = poisson_encode(\n",
        "            imgs, num_steps=NUM_STEPS,\n",
        "            max_rate_hz=MAX_RATE_HZ, dt=DT\n",
        "        ).to(device)\n",
        "\n",
        "        spk_rec = model(spikes)\n",
        "\n",
        "        # correct decoding\n",
        "        counts = spk_rec.sum(dim=0)      # [B,10]\n",
        "        preds  = counts.argmax(dim=1)\n",
        "\n",
        "        total_correct += (preds == labels).sum().item()\n",
        "        total_seen    += labels.size(0)\n",
        "\n",
        "        del spikes, spk_rec\n",
        "\n",
        "    acc = total_correct / total_seen\n",
        "    print(f\"Test acc={acc:.4f}\")\n",
        "    return acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD-FsAbSnSv4"
      },
      "outputs": [],
      "source": [
        "train_hist = {\"loss\": [], \"acc\": [], \"val_acc\": []}\n",
        "\n",
        "for ep in range(1, 16):  # bump to e.g. 5–10 on GPU\n",
        "    tr_loss, tr_acc = train_one_epoch(ep)\n",
        "    va_acc = evaluate()\n",
        "    train_hist[\"loss\"].append(tr_loss)\n",
        "    train_hist[\"acc\"].append(tr_acc)\n",
        "    train_hist[\"val_acc\"].append(va_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2odZHOenaBN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "@torch.no_grad()\n",
        "def viz_one_example():\n",
        "    model.eval()\n",
        "\n",
        "    imgs, labels = next(iter(test_loader))\n",
        "    imgs = imgs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # reproducible spikes for this example\n",
        "    g = torch.Generator(device=imgs.device).manual_seed(0)\n",
        "    spikes = poisson_encode(\n",
        "        imgs[:1],\n",
        "        num_steps=NUM_STEPS,\n",
        "        max_rate_hz=MAX_RATE_HZ,\n",
        "        dt=DT,\n",
        "        rng=g,\n",
        "    ).to(device)\n",
        "\n",
        "    # run model, record membranes\n",
        "    spk_rec, (mem1, mem2) = model(spikes, return_mem=True)  # [T,1,10], [T,1,H], [T,1,10]\n",
        "\n",
        "    spk = spk_rec[:, 0].cpu().numpy()   # [T,10]\n",
        "    counts = spk.sum(axis=0)            # [10]\n",
        "    pred = int(counts.argmax())\n",
        "    true = int(labels[0].item())\n",
        "\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(8, 6))\n",
        "    # make sure axes is always indexable as an array\n",
        "    axes = np.atleast_1d(axes)\n",
        "\n",
        "    # --- Raster: time vs class id ---\n",
        "    t_idx, c_idx = np.where(spk > 0.5)\n",
        "    axes[0].scatter(t_idx, c_idx, s=8)\n",
        "    axes[0].invert_yaxis()\n",
        "    axes[0].set_title(f\"Output spikes over time — true={true}, pred={pred}\")\n",
        "    axes[0].set_xlabel(\"time step\")\n",
        "    axes[0].set_ylabel(\"class id\")\n",
        "\n",
        "    # --- Spike counts bar plot ---\n",
        "    axes[1].bar(np.arange(10), counts)\n",
        "    axes[1].set_xlabel(\"class\")\n",
        "    axes[1].set_ylabel(\"spike count\")\n",
        "    axes[1].set_title(\"Spike counts over window\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "viz_one_example()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "spiking-neural-networks (3.12.8)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
